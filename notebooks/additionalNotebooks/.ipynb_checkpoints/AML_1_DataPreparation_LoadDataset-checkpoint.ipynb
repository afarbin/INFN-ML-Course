{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[![Google Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/afarbin/INFN-ML-Course/blob/master/notebooks/Classification-workflow-sklearn.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load your ML dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on [CSV files](https://tools.ietf.org/html/rfc4180). \n",
    "\n",
    "We will explore:\n",
    "\n",
    "* Load CSV Files with the Python Standard Library\n",
    "* Load CSV Files with NumPy\n",
    "* Load CSV Files with Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review in particular:\n",
    "\n",
    "* ***File Header***\n",
    "\n",
    "* ***Comments***\n",
    "\n",
    "* ***Delimiter***\n",
    "\n",
    "* ***Quotes***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some test data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the famous \"Pima Indians dataset\". The data was freely available from the UCI ML Repository, and can now be found elsewhere. For your convenience it can be downloaded within the course material for this lecture, e.g.:\n",
    "   * https://drive.google.com/open?id=12pjLYLeuZ__4SVPuz6zL9QQpPiwbVYDKz_rsn4eeHzI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--@ 1 bonacor  staff    23K Apr  9 11:59 pima-indians-diabetes.data.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -trlh pima-indians-diabetes.data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,148,72,35,0,33.6,0.627,50,1\r\n",
      "1,85,66,29,0,26.6,0.351,31,0\r\n",
      "8,183,64,0,0,23.3,0.672,32,1\r\n",
      "1,89,66,23,94,28.1,0.167,21,0\r\n",
      "0,137,40,35,168,43.1,2.288,33,1\r\n",
      "5,116,74,0,0,25.6,0.201,30,0\r\n",
      "3,78,50,32,88,31.0,0.248,26,1\r\n",
      "10,115,0,0,0,35.3,0.134,29,0\r\n",
      "2,197,70,45,543,30.5,0.158,53,1\r\n",
      "8,125,96,0,0,0.0,0.232,54,1\r\n",
      "4,110,92,0,0,37.6,0.191,30,0\r\n",
      "10,168,74,0,0,38.0,0.537,34,1\r\n",
      "10,139,80,0,0,27.1,1.441,57,0\r\n",
      "1,189,60,23,846,30.1,0.398,59,1\r\n",
      "5,166,72,19,175,25.8,0.587,51,1\r\n",
      "7,100,0,0,0,30.0,0.484,32,1\r\n",
      "0,118,84,47,230,45.8,0.551,31,1\r\n",
      "7,107,74,0,0,29.6,0.254,31,1\r\n",
      "1,103,30,38,83,43.3,0.183,33,0\r\n",
      "1,115,70,30,96,34.6,0.529,32,1\r\n",
      "3,126,88,41,235,39.3,0.704,27,0\r\n",
      "8,99,84,0,0,35.4,0.388,50,0\r\n",
      "7,196,90,0,0,39.8,0.451,41,1\r\n",
      "9,119,80,35,0,29.0,0.263,29,1\r\n",
      "11,143,94,33,146,36.6,0.254,51,1\r\n",
      "10,125,70,26,115,31.1,0.205,41,1\r\n",
      "7,147,76,0,0,39.4,0.257,43,1\r\n",
      "1,97,66,15,140,23.2,0.487,22,0\r\n",
      "13,145,82,19,110,22.2,0.245,57,0\r\n",
      "5,117,92,0,0,34.1,0.337,38,0\r\n",
      "5,109,75,26,0,36.0,0.546,60,0\r\n",
      "3,158,76,36,245,31.6,0.851,28,1\r\n",
      "3,88,58,11,54,24.8,0.267,22,0\r\n",
      "6,92,92,0,0,19.9,0.188,28,0\r\n",
      "10,122,78,31,0,27.6,0.512,45,0\r\n",
      "4,103,60,33,192,24.0,0.966,33,0\r\n",
      "11,138,76,0,0,33.2,0.420,35,0\r\n",
      "9,102,76,37,0,32.9,0.665,46,1\r\n",
      "2,90,68,42,0,38.2,0.503,27,1\r\n",
      "4,111,72,47,207,37.1,1.390,56,1\r\n",
      "3,180,64,25,70,34.0,0.271,26,0\r\n",
      "7,133,84,0,0,40.2,0.696,37,0\r\n",
      "7,106,92,18,0,22.7,0.235,48,0\r\n",
      "9,171,110,24,240,45.4,0.721,54,1\r\n",
      "7,159,64,0,0,27.4,0.294,40,0\r\n",
      "0,180,66,39,0,42.0,1.893,25,1\r\n",
      "1,146,56,0,0,29.7,0.564,29,0\r\n",
      "2,71,70,27,0,28.0,0.586,22,0\r\n",
      "7,103,66,32,0,39.1,0.344,31,1\r\n",
      "7,105,0,0,0,0.0,0.305,24,0\r\n"
     ]
    }
   ],
   "source": [
    "!head -50 pima-indians-diabetes.data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV Files with the Python Standard Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More info on `csv.reader()` can be found in the [CSV File Reading and Writing in the Python API](https://docs.python.org/2/library/csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: file open options are documented [here](https://docs.python.org/3/library/functions.html#open)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "raw_data = open(filename, 'rt')           # t=text mode open for r=reading (both are defaults)\n",
    "reader = csv.reader(raw_data, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "x = list(reader)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.array(x).astype('float')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV Files with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information on the `numpy.loadtxt()` function can be found on the [NumPy API documentation for loadtxt](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.loadtxt.html). The code above loads the file as a `numpy.ndarray`: more info on the [NumPy API documentation for ndarray](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.ndarray.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "raw_data = open(filename, 'rt')\n",
    "data = loadtxt(raw_data, delimiter=\",\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV Files with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `pandas.read_csv()` function (more info [here](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)). The function returns a `pandas.DataFrame` (more information on the [Pandas API documentation for DataFrame](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html) that one can immediately process, summarize, plot, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = 'pima-indians-diabetes.data.csv'\n",
    "nomi = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = read_csv(filename, names=nomi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did:\n",
    "\n",
    "* we discussed the need to import data\n",
    "* we discussed the CSV format \n",
    "* we discussed peculiarities to check in the file before importing\n",
    "* we familiarized with 3 ways to load data into Python (for ML purposes). We discussed why method 3 might be a good choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What's next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It is time to start looking at the data we loaded. We will discover how to use simple descriptive statistics to better understand our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
